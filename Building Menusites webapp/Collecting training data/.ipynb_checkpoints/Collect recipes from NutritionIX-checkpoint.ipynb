{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2, time, random, re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import urllib\n",
    "\n",
    "from sqlalchemy import create_engine, Column, Integer, String, Float, ForeignKey, UniqueConstraint\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import relationship, sessionmaker\n",
    "import sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def search_allrecipes(searchstring):\n",
    "    query = {\"wt\": searchstring}\n",
    "    query = urllib.urlencode(query)\n",
    "    url = str(\"http://allrecipes.com/search/results/?\" + query)\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_allrecipes_urls(start_url):\n",
    "    hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "           'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "           'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "           'Accept-Encoding': 'none',\n",
    "           'Accept-Language': 'en-US,en;q=0.8','Connection': 'keep-alive'}\n",
    "    recipeurls = []\n",
    "    try:\n",
    "        soup = BeautifulSoup(urllib2.urlopen(urllib2.Request(start_url, headers=hdr)).read())\n",
    "        url_list = []\n",
    "        for recipeurl in soup.find_all(href=re.compile(\"^/recipe/[0-9]+/.+/\")):\n",
    "            recipeurls.append(str(\"http://allrecipes.com\" + recipeurl.attrs[\"href\"]))\n",
    "    except:\n",
    "        print \"Error, skipping.\"\n",
    "    return list(set(recipeurls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://allrecipes.com/search/results/?wt=burger'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_allrecipes(\"burger\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andylane/anaconda2/envs/insight/lib/python2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 174 of the file /home/andylane/anaconda2/envs/insight/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "seed = extract_allrecipes_urls(\"http://allrecipes.com/recipes/?grouping=all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urls = []\n",
    "for item in seed:\n",
    "    urls.extend(extract_allrecipes_urls(item))\n",
    "urls = list(set(urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'current_urls' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-227d2363ffe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnew_urls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_urls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'current_urls' is not defined"
     ]
    }
   ],
   "source": [
    "new_urls = current_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('1', '46', '1')\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "seed = [\"http://allrecipes.com/recipes/96/salad/?internalSource=hubcard&referringContentType=search%20results&clickId=cardslot%201\"]\n",
    "master_url_list = []\n",
    "new_urls = seed\n",
    "while i <= 5:\n",
    "    current_urls = new_urls\n",
    "    new_urls = []\n",
    "    for item in current_urls:\n",
    "        new_urls.extend(extract_allrecipes_urls(item))\n",
    "    master_url_list.extend(list(set(new_urls)))\n",
    "    i = i+1\n",
    "    print(str(i), str(len(master_url_list)), str(len(current_urls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(set(current_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is necessary to remove some non-recipe pages that the regex misses... total hack\n",
    "for item in master_url_list:\n",
    "    if item.find(\"photos\") > 0:\n",
    "        master_url_list.remove(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scrapeme = list(set(master_url_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dbname = 'restaurants'\n",
    "username = 'andylane'\n",
    "engine = create_engine('postgres://%s@localhost/%s'%(username,dbname))\n",
    "print(engine.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Base = declarative_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Recipe(Base):\n",
    "    __tablename__ = 'recipes'\n",
    "    \n",
    "    id = Column(Integer, primary_key=True)\n",
    "    name = Column(String)\n",
    "    url = Column(String, unique=True)\n",
    "    calories = Column(Integer)\n",
    "    fat = Column(Float)\n",
    "    carbs = Column(Float)\n",
    "    protein = Column(Float)\n",
    "    cholesterol = Column(Float)\n",
    "    sodium = Column(Float)\n",
    "    servings = Column(Integer)\n",
    "    #ingredients = \n",
    "    #__table_args__ = {'extend_existing': True}\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"<Recipe(name='%s', url='%s')>\" % (\n",
    "            self.name, self.url)\n",
    "    \n",
    "class Ingredient(Base):\n",
    "    __tablename__ = 'ingredients'\n",
    "    id = Column(Integer, primary_key = True)\n",
    "    ingredient = Column(String, nullable = False)\n",
    "    recipe_id = Column(Integer, ForeignKey('recipes.id'))\n",
    "    \n",
    "    recipe = relationship(Recipe, back_populates = 'ingredients')\n",
    "    #__table_args__ = {'extend_existing': True}\n",
    "    def __repr__(self):\n",
    "        return \"<Ingredient(ingredient='%s')>\" % self.ingredient\n",
    "\n",
    "Recipe.ingredients = relationship(\"Ingredient\", order_by=Ingredient.id, back_populates=\"recipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Base.metadata.create_all(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(master_url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(scrapeme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session.query(Recipe).filter_by(url=str(\"http://allrecipes.com/recipe/214675/spicy-chipotle-grilled-shrimp/\")).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "failedurls = []\n",
    "\n",
    "hdr = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
    "       'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
    "       'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
    "       'Accept-Encoding': 'none',\n",
    "       'Accept-Language': 'en-US,en;q=0.8','Connection': 'keep-alive'}\n",
    "\n",
    "for url in scrapeme:\n",
    "    session.rollback()\n",
    "    if len(session.query(Recipe).filter_by(url=str(url)).all()) == 0:\n",
    "        try:\n",
    "            soup = BeautifulSoup(urllib2.urlopen(urllib2.Request(url, headers=hdr)).read())\n",
    "            url = url\n",
    "            name = soup.find_all(\"h1\", itemprop=\"name\")[0].get_text()\n",
    "            fat = soup.find_all(\"li\", itemprop=\"fatContent\")[0].span.get_text()\n",
    "            calories = soup.find_all(\"li\", itemprop=\"calories\")[0].span.get_text()\n",
    "            carbs = soup.find_all(\"li\", itemprop=\"carbohydrateContent\")[0].span.get_text()\n",
    "            protein = soup.find_all(\"li\", itemprop=\"proteinContent\")[0].span.get_text()\n",
    "            cholesterol = soup.find_all(\"li\", itemprop=\"cholesterolContent\")[0].span.get_text()\n",
    "            sodium = soup.find_all(\"li\", itemprop=\"sodiumContent\")[0].span.get_text()\n",
    "            servings = soup.find_all(\"meta\", itemprop=\"recipeYield\")[0][\"content\"]\n",
    "            ingredients = []\n",
    "            for ingredient in soup.find_all(\"span\", class_=\"recipe-ingred_txt added\"):\n",
    "                ingredients.append(ingredient.contents)\n",
    "            session.add(Recipe(\n",
    "                name=name, \n",
    "                fat=fat, \n",
    "                calories=calories,\n",
    "                carbs=carbs, \n",
    "                protein=protein,\n",
    "                cholesterol=cholesterol,\n",
    "                sodium=sodium,\n",
    "                servings=servings,\n",
    "                url=url,\n",
    "                ingredients=[Ingredient(ingredient = str(item)) for item in ingredients]\n",
    "                               ))\n",
    "            try:\n",
    "                session.commit()\n",
    "            except sqlalchemy.exc.DataError:\n",
    "                print(\"Sanitize your data, man\")\n",
    "                session.rollback()\n",
    "                failedurls.append(url)\n",
    "            except sqlalchemy.exc.InvalidRequestError:\n",
    "                print(\"probably not unique\")\n",
    "                session.rollback()\n",
    "        except:\n",
    "            print url\n",
    "    else:\n",
    "        print(str(url) + \" already in database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "session.rollback()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [insight]",
   "language": "python",
   "name": "Python [insight]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
